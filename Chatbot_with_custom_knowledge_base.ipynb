{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21a5c823",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "##### This notebook has all the code you need to create your own chatbot with custom knowledge base using GPT-3.\n",
    "\n",
    "#### Download the data for your custom knowledge base\n",
    "##### For the demonstration purposes we are going to use ----- as our knowledge base. You can download them to your local folder from the github repository by running the code below. Alternatively, you can put your own custom data into the local folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e08c2f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'context_data'...\n"
     ]
    }
   ],
   "source": [
    "! git clone https://github.com/irina1nik/context_data.git\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8821478",
   "metadata": {},
   "source": [
    "#### Install the dependicies\n",
    "##### Run the code below to install the depencies we need for our functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00158597",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install llama-index==0.5.6\n",
    "!pip install langchain==0.0.148"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6baa0f96",
   "metadata": {},
   "source": [
    "#### Define the functions\n",
    "##### The following code defines the functions we need to construct the index and query it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a01dab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import SimpleDirectoryReader, GPTListIndex, readers, GPTVectorStoreIndex, LLMPredictor, PromptHelper,load_index_from_storage,StorageContext, ServiceContext\n",
    "from langchain import OpenAI\n",
    "import sys\n",
    "import os\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "def construct_index(directory_path):\n",
    "    # set maximum input size\n",
    "    max_input_size = 4096\n",
    "    # set number of output tokens\n",
    "    num_outputs = 2000\n",
    "    # set maximum chunk overlap\n",
    "    max_chunk_overlap = 20\n",
    "    # set chunk size limit\n",
    "    chunk_size_limit = 600 \n",
    "\n",
    "    # define prompt helper\n",
    "    prompt_helper = PromptHelper(max_input_size, num_outputs, max_chunk_overlap, chunk_size_limit=chunk_size_limit)\n",
    "\n",
    "    # define LLM\n",
    "    llm_predictor = LLMPredictor(llm=OpenAI(temperature=0.5, model_name=\"text-davinci-003\", max_tokens=num_outputs))\n",
    " \n",
    "    documents = SimpleDirectoryReader(directory_path).load_data()\n",
    "    \n",
    "    service_context = ServiceContext.from_defaults(llm_predictor=llm_predictor, prompt_helper=prompt_helper)\n",
    "    index = GPTVectorStoreIndex.from_documents(documents, service_context=service_context)\n",
    "\n",
    "    index.storage_context.persist(persist_dir=\"index.json\")\n",
    "\n",
    "    return index\n",
    "\n",
    "def ask_ai():\n",
    "    storage_context = StorageContext.from_defaults(persist_dir=\"index.json\")\n",
    "    index = load_index_from_storage(storage_context)\n",
    "    while True: \n",
    "        query = input(\"What do you want to ask? \")\n",
    "        query_engine = index.as_query_engine()\n",
    "        response = query_engine.query(query)\n",
    "        display(Markdown(f\"Response: <b>{response.response}</b>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0c9015",
   "metadata": {},
   "source": [
    "#### Set OpenAI API Key\n",
    "##### You need an OPENAI API key to be able to run this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffb2474",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = input(\"Paste your OpenAI key here and hit enter:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58d95a4",
   "metadata": {},
   "source": [
    "#### Construct an index\n",
    "##### Now we are ready to construct the index. This will take every file in the folder 'data', split it into chunks, and embed it with OpenAI's embeddings API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f157b0a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<llama_index.indices.vector_store.base.GPTVectorStoreIndex at 0x223a3b2fc40>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "construct_index(\"context_data/data\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2102e3a",
   "metadata": {},
   "source": [
    "#### Ask questions\n",
    "###### It's time to have fun and test our AI. Run the function that queries GPT and type your question into the input.\n",
    "\n",
    "##### If you've used the provided example data for your custom knowledge base, here are a few questions that you can ask:\n",
    "\n",
    "##### Why people cook at home? Make classification\n",
    "##### Make classification about what frustrates people about cooking?\n",
    "##### Brainstorm marketing campaign ideas for an air fryer that would appeal people that cook at home\n",
    "##### Which kitchen appliences people use most often?\n",
    "##### What people like about cooking at home?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de4e175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What do you want to ask? what people like about cooking at home\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Response: <b>\n",
       "People like cooking at home because it allows them to relax and unwind after a long day, be in control of what goes into their meals, customize their meals to their family's preferences, spend time with their family in the kitchen, experiment with different recipes and ingredients, and make healthier and more affordable meals than eating out all the time.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ask_ai()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80eda7f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
